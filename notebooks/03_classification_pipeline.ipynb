{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 3: Clasificaci√≥n con Descriptores Cl√°sicos y Deep Learning\n",
        "\n",
        "**Taller 3 - Clasificaci√≥n de Im√°genes M√©dicas**\n",
        "\n",
        "Universidad Nacional de Colombia - Visi√≥n por Computador\n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos\n",
        "1. Crear matriz de caracter√≠sticas para todo el dataset\n",
        "2. Normalizaci√≥n de features (StandardScaler)\n",
        "3. Reducci√≥n de dimensionalidad (PCA)\n",
        "4. Entrenar y evaluar m√∫ltiples clasificadores:\n",
        "   - Support Vector Machine (SVM)\n",
        "   - Random Forest\n",
        "   - k-Nearest Neighbors (k-NN)\n",
        "   - Logistic Regression\n",
        "   - Convolutional Neural Network (CNN)\n",
        "5. Validaci√≥n cruzada\n",
        "6. An√°lisis de importancia de features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuraci√≥n e Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports est√°ndar\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Agregar src al path\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "# Imports de nuestros m√≥dulos\n",
        "from src.data_loader import load_image_paths, split_by_set, labels_to_numeric\n",
        "from src.preprocessing import read_and_preprocess\n",
        "from src.features import build_feature_matrix, normalize_features, apply_pca\n",
        "from src.classical_models import (\n",
        "    get_default_models, \n",
        "    train_all_models, \n",
        "    cross_validate_models,\n",
        "    get_feature_importance_rf,\n",
        "    get_feature_importance_linear\n",
        ")\n",
        "from src.evaluation import compute_metrics, print_metrics, compare_models\n",
        "from src.visualization import plot_confusion_matrix, plot_roc_curve, plot_training_history\n",
        "\n",
        "# Configuraci√≥n\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "print(\"Imports completados correctamente ‚úì\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar datos\n",
        "DATA_DIR = \"../data/chest_xray/chest_xray\"\n",
        "paths, labels = load_image_paths(DATA_DIR)\n",
        "(paths_train, labels_train), (paths_val, labels_val), (paths_test, labels_test) = split_by_set(paths, labels)\n",
        "\n",
        "# Convertir etiquetas a num√©rico\n",
        "y_train = labels_to_numeric(labels_train)\n",
        "y_val = labels_to_numeric(labels_val)\n",
        "y_test = labels_to_numeric(labels_test)\n",
        "\n",
        "print(\"Datos cargados:\")\n",
        "print(f\"  Train: {len(paths_train)} im√°genes\")\n",
        "print(f\"  Val:   {len(paths_val)} im√°genes\")\n",
        "print(f\"  Test:  {len(paths_test)} im√°genes\")\n",
        "print(f\"\\nDistribuci√≥n de clases en train:\")\n",
        "print(f\"  NORMAL (0):    {np.sum(y_train == 0)}\")\n",
        "print(f\"  PNEUMONIA (1): {np.sum(y_train == 1)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extracci√≥n de Caracter√≠sticas\n",
        "\n",
        "Construimos la matriz de caracter√≠sticas usando todos los descriptores implementados (HOG, Hu, Fourier, LBP, GLCM, Gabor).\n",
        "\n",
        "‚ö†Ô∏è **Nota**: Este proceso puede tardar varios minutos dependiendo del tama√±o del dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Extraer caracter√≠sticas para todos los conjuntos\n",
        "print(\"Extrayendo caracter√≠sticas del conjunto de entrenamiento...\")\n",
        "X_train = build_feature_matrix(paths_train, show_progress=True)\n",
        "\n",
        "print(\"\\nExtrayendo caracter√≠sticas del conjunto de validaci√≥n...\")\n",
        "X_val = build_feature_matrix(paths_val, show_progress=True)\n",
        "\n",
        "print(\"\\nExtrayendo caracter√≠sticas del conjunto de prueba...\")\n",
        "X_test = build_feature_matrix(paths_test, show_progress=True)\n",
        "\n",
        "print(f\"\\n‚úì Extracci√≥n completada:\")\n",
        "print(f\"  X_train: {X_train.shape}\")\n",
        "print(f\"  X_val:   {X_val.shape}\")\n",
        "print(f\"  X_test:  {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Normalizaci√≥n de Features\n",
        "\n",
        "Usamos StandardScaler para normalizar las caracter√≠sticas (media=0, std=1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar caracter√≠sticas\n",
        "X_train_norm, X_val_norm, X_test_norm, scaler = normalize_features(X_train, X_val, X_test)\n",
        "\n",
        "print(\"Caracter√≠sticas normalizadas:\")\n",
        "print(f\"  Media de X_train_norm: {X_train_norm.mean():.6f}\")\n",
        "print(f\"  Std de X_train_norm:   {X_train_norm.std():.6f}\")\n",
        "\n",
        "# Visualizar distribuci√≥n antes y despu√©s\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Muestra de features antes de normalizar\n",
        "sample_features = X_train[:, :5]\n",
        "axes[0].boxplot(sample_features)\n",
        "axes[0].set_title('Features Originales (primeras 5)')\n",
        "axes[0].set_xlabel('Feature')\n",
        "axes[0].set_ylabel('Valor')\n",
        "\n",
        "# Despu√©s de normalizar\n",
        "sample_features_norm = X_train_norm[:, :5]\n",
        "axes[1].boxplot(sample_features_norm)\n",
        "axes[1].set_title('Features Normalizadas (primeras 5)')\n",
        "axes[1].set_xlabel('Feature')\n",
        "axes[1].set_ylabel('Valor (estandarizado)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/03_normalization.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Reducci√≥n de Dimensionalidad (PCA)\n",
        "\n",
        "Aplicamos PCA para reducir la dimensionalidad preservando el 95% de la varianza.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aplicar PCA\n",
        "X_train_pca, X_val_pca, X_test_pca, pca = apply_pca(X_train_norm, X_val_norm, X_test_norm, variance_ratio=0.95)\n",
        "\n",
        "print(\"Reducci√≥n de dimensionalidad con PCA:\")\n",
        "print(f\"  Dimensiones originales: {X_train_norm.shape[1]}\")\n",
        "print(f\"  Dimensiones despu√©s de PCA: {X_train_pca.shape[1]}\")\n",
        "print(f\"  Reducci√≥n: {100*(1 - X_train_pca.shape[1]/X_train_norm.shape[1]):.1f}%\")\n",
        "print(f\"  Varianza explicada: {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
        "\n",
        "# Visualizar varianza explicada acumulada\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(cumsum, 'b-', linewidth=2)\n",
        "plt.axhline(y=0.95, color='r', linestyle='--', label='95% varianza')\n",
        "plt.xlabel('N√∫mero de componentes')\n",
        "plt.ylabel('Varianza explicada acumulada')\n",
        "plt.title('Varianza Explicada por PCA')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('../results/03_pca_variance.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Entrenamiento de Clasificadores Cl√°sicos\n",
        "\n",
        "Entrenamos y evaluamos m√∫ltiples clasificadores:\n",
        "- SVM con kernel lineal\n",
        "- SVM con kernel RBF\n",
        "- Random Forest\n",
        "- k-NN (k=5)\n",
        "- Regresi√≥n Log√≠stica\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener modelos por defecto\n",
        "models = get_default_models()\n",
        "print(\"Modelos a entrenar:\")\n",
        "for name in models.keys():\n",
        "    print(f\"  - {name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Entrenar y evaluar todos los modelos\n",
        "results = train_all_models(\n",
        "    models,\n",
        "    X_train_pca, y_train,\n",
        "    X_val_pca, y_val,\n",
        "    X_test_pca, y_test,\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar resultados\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARACI√ìN DE MODELOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Crear tabla de resultados\n",
        "import pandas as pd\n",
        "\n",
        "comparison_data = []\n",
        "for name, res in results.items():\n",
        "    comparison_data.append({\n",
        "        'Modelo': name,\n",
        "        'Val Accuracy': f\"{res['val_accuracy']:.4f}\",\n",
        "        'Val F1': f\"{res['val_f1']:.4f}\",\n",
        "        'Test Accuracy': f\"{res['test_accuracy']:.4f}\",\n",
        "        'Test F1': f\"{res['test_f1']:.4f}\"\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Mejor modelo\n",
        "best_model_name = max(results, key=lambda x: results[x]['test_f1'])\n",
        "print(f\"\\nüèÜ Mejor modelo (por F1 en test): {best_model_name}\")\n",
        "print(f\"   Test F1: {results[best_model_name]['test_f1']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar comparaci√≥n\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "model_names = list(results.keys())\n",
        "test_acc = [results[m]['test_accuracy'] for m in model_names]\n",
        "test_f1 = [results[m]['test_f1'] for m in model_names]\n",
        "\n",
        "# Accuracy\n",
        "axes[0].barh(model_names, test_acc, color='steelblue')\n",
        "axes[0].set_xlabel('Accuracy')\n",
        "axes[0].set_title('Test Accuracy por Modelo')\n",
        "axes[0].set_xlim([0.5, 1.0])\n",
        "for i, v in enumerate(test_acc):\n",
        "    axes[0].text(v + 0.01, i, f'{v:.3f}', va='center')\n",
        "\n",
        "# F1 Score\n",
        "axes[1].barh(model_names, test_f1, color='coral')\n",
        "axes[1].set_xlabel('F1 Score')\n",
        "axes[1].set_title('Test F1 Score por Modelo')\n",
        "axes[1].set_xlim([0.5, 1.0])\n",
        "for i, v in enumerate(test_f1):\n",
        "    axes[1].text(v + 0.01, i, f'{v:.3f}', va='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/03_model_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Validaci√≥n Cruzada\n",
        "\n",
        "Evaluamos los modelos con validaci√≥n cruzada de 5 folds para obtener una estimaci√≥n m√°s robusta del rendimiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Validaci√≥n cruzada\n",
        "cv_results = cross_validate_models(models, X_train_pca, y_train, cv=5, scoring='f1', verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar resultados de CV\n",
        "cv_means = [cv_results[m][0] for m in model_names]\n",
        "cv_stds = [cv_results[m][1] for m in model_names]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(model_names, cv_means, xerr=cv_stds, color='teal', capsize=5)\n",
        "plt.xlabel('F1 Score (CV)')\n",
        "plt.title('Validaci√≥n Cruzada (5-fold F1 Score)')\n",
        "plt.xlim([0.5, 1.0])\n",
        "for i, (mean, std) in enumerate(zip(cv_means, cv_stds)):\n",
        "    plt.text(mean + std + 0.02, i, f'{mean:.3f}¬±{std:.3f}', va='center')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/03_cross_validation.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Matrices de Confusi√≥n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar matrices de confusi√≥n para todos los modelos\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, (name, res) in enumerate(results.items()):\n",
        "    if idx < 5:\n",
        "        cm = res['confusion_matrix']\n",
        "        ax = axes[idx]\n",
        "        im = ax.imshow(cm, cmap='Blues')\n",
        "        ax.set_title(f'{name}\\nAcc={res[\"test_accuracy\"]:.3f}, F1={res[\"test_f1\"]:.3f}')\n",
        "        ax.set_xticks([0, 1])\n",
        "        ax.set_yticks([0, 1])\n",
        "        ax.set_xticklabels(['NORMAL', 'PNEUMONIA'])\n",
        "        ax.set_yticklabels(['NORMAL', 'PNEUMONIA'])\n",
        "        ax.set_xlabel('Predicho')\n",
        "        ax.set_ylabel('Real')\n",
        "        \n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                ax.text(j, i, str(cm[i, j]), ha='center', va='center', \n",
        "                       color='white' if cm[i, j] > cm.max()/2 else 'black', fontsize=14)\n",
        "\n",
        "# Ocultar el √∫ltimo subplot\n",
        "axes[5].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/03_confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Importancia de Caracter√≠sticas\n",
        "\n",
        "Analizamos qu√© caracter√≠sticas son m√°s importantes seg√∫n Random Forest y modelos lineales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importancia de caracter√≠sticas - Random Forest\n",
        "rf_model = results['RandomForest']['model']\n",
        "top_features_rf = get_feature_importance_rf(rf_model, top_n=20, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importancia de caracter√≠sticas - SVM Lineal\n",
        "svm_model = results['SVM-linear']['model']\n",
        "top_features_svm = get_feature_importance_linear(svm_model, top_n=20, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar importancia de caracter√≠sticas\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Random Forest\n",
        "importances_rf = rf_model.feature_importances_\n",
        "top_idx_rf = np.argsort(importances_rf)[-15:]\n",
        "axes[0].barh(range(15), importances_rf[top_idx_rf], color='forestgreen')\n",
        "axes[0].set_yticks(range(15))\n",
        "axes[0].set_yticklabels([f'PC{i}' for i in top_idx_rf])\n",
        "axes[0].set_xlabel('Importancia')\n",
        "axes[0].set_title('Top 15 Features - Random Forest')\n",
        "\n",
        "# SVM Lineal\n",
        "coefs_svm = np.abs(svm_model.coef_)[0]\n",
        "top_idx_svm = np.argsort(coefs_svm)[-15:]\n",
        "axes[1].barh(range(15), coefs_svm[top_idx_svm], color='darkorange')\n",
        "axes[1].set_yticks(range(15))\n",
        "axes[1].set_yticklabels([f'PC{i}' for i in top_idx_svm])\n",
        "axes[1].set_xlabel('|Coeficiente|')\n",
        "axes[1].set_title('Top 15 Features - SVM Lineal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/03_feature_importance.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Clasificaci√≥n con CNN (Deep Learning)\n",
        "\n",
        "Entrenamos una CNN simple que usa directamente las im√°genes en lugar de las caracter√≠sticas extra√≠das manualmente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports para Deep Learning\n",
        "import torch\n",
        "from src.deep_learning import SimpleCNN, ChestXrayDataset, create_dataloaders, train_cnn, evaluate_cnn\n",
        "from src.deep_learning.models import get_device\n",
        "\n",
        "device = get_device()\n",
        "print(f\"Dispositivo: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear DataLoaders\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    paths_train, labels_train,\n",
        "    paths_val, labels_val,\n",
        "    paths_test, labels_test,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches:   {len(val_loader)}\")\n",
        "print(f\"Test batches:  {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear y entrenar modelo CNN\n",
        "model = SimpleCNN()\n",
        "print(f\"Arquitectura del modelo:\")\n",
        "print(model)\n",
        "print(f\"\\nPar√°metros entrenables: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Entrenar CNN (reducir √©pocas para demo, aumentar para mejores resultados)\n",
        "EPOCHS = 10  # Aumentar a 30-50 para mejores resultados\n",
        "\n",
        "cnn_result = train_cnn(\n",
        "    model, \n",
        "    train_loader, \n",
        "    val_loader,\n",
        "    labels_train=labels_train,\n",
        "    epochs=EPOCHS,\n",
        "    lr=1e-4,\n",
        "    use_class_weights=True,\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluar CNN en test\n",
        "print(\"\\nEvaluaci√≥n de CNN en conjunto de TEST:\")\n",
        "cnn_metrics = evaluate_cnn(cnn_result['model'], test_loader, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar historial de entrenamiento\n",
        "if 'history' in cnn_result:\n",
        "    history = cnn_result['history']\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    \n",
        "    # Loss\n",
        "    axes[0].plot(history['train_loss'], 'b-', label='Train')\n",
        "    axes[0].set_xlabel('√âpoca')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Accuracy\n",
        "    axes[1].plot(history['val_accuracy'], 'g-', label='Val')\n",
        "    axes[1].set_xlabel('√âpoca')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].set_title('Validation Accuracy')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # F1\n",
        "    axes[2].plot(history['val_f1'], 'r-', label='Val')\n",
        "    axes[2].set_xlabel('√âpoca')\n",
        "    axes[2].set_ylabel('F1 Score')\n",
        "    axes[2].set_title('Validation F1 Score')\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../results/03_cnn_training.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de confusi√≥n y ROC para CNN\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Matriz de confusi√≥n\n",
        "cm = cnn_metrics['confusion_matrix']\n",
        "im = axes[0].imshow(cm, cmap='Blues')\n",
        "axes[0].set_title(f'CNN - Matriz de Confusi√≥n\\nAcc={cnn_metrics[\"accuracy\"]:.3f}, F1={cnn_metrics[\"f1\"]:.3f}')\n",
        "axes[0].set_xticks([0, 1])\n",
        "axes[0].set_yticks([0, 1])\n",
        "axes[0].set_xticklabels(['NORMAL', 'PNEUMONIA'])\n",
        "axes[0].set_yticklabels(['NORMAL', 'PNEUMONIA'])\n",
        "axes[0].set_xlabel('Predicho')\n",
        "axes[0].set_ylabel('Real')\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        axes[0].text(j, i, str(cm[i, j]), ha='center', va='center',\n",
        "                    color='white' if cm[i, j] > cm.max()/2 else 'black', fontsize=14)\n",
        "\n",
        "# Curva ROC\n",
        "axes[1].plot(cnn_metrics['fpr'], cnn_metrics['tpr'], 'b-', linewidth=2, \n",
        "             label=f'CNN (AUC = {cnn_metrics[\"auc\"]:.3f})')\n",
        "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "axes[1].set_xlabel('False Positive Rate')\n",
        "axes[1].set_ylabel('True Positive Rate')\n",
        "axes[1].set_title('Curva ROC - CNN')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/03_cnn_evaluation.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Comparaci√≥n Final: Cl√°sicos vs Deep Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparaci√≥n final\n",
        "print(\"=\"*70)\n",
        "print(\"COMPARACI√ìN FINAL: T√âCNICAS CL√ÅSICAS vs DEEP LEARNING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Tabla comparativa\n",
        "all_results = []\n",
        "for name, res in results.items():\n",
        "    all_results.append({\n",
        "        'Modelo': name,\n",
        "        'Tipo': 'Cl√°sico',\n",
        "        'Test Acc': res['test_accuracy'],\n",
        "        'Test F1': res['test_f1']\n",
        "    })\n",
        "\n",
        "all_results.append({\n",
        "    'Modelo': 'SimpleCNN',\n",
        "    'Tipo': 'Deep Learning',\n",
        "    'Test Acc': cnn_metrics['accuracy'],\n",
        "    'Test F1': cnn_metrics['f1']\n",
        "})\n",
        "\n",
        "comparison_final = pd.DataFrame(all_results)\n",
        "comparison_final = comparison_final.sort_values('Test F1', ascending=False)\n",
        "print(comparison_final.to_string(index=False))\n",
        "\n",
        "# Mejor modelo general\n",
        "best_overall = comparison_final.iloc[0]\n",
        "print(f\"\\nüèÜ MEJOR MODELO GENERAL: {best_overall['Modelo']}\")\n",
        "print(f\"   Tipo: {best_overall['Tipo']}\")\n",
        "print(f\"   Test Accuracy: {best_overall['Test Acc']:.4f}\")\n",
        "print(f\"   Test F1 Score: {best_overall['Test F1']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gr√°fico comparativo final\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "models_sorted = comparison_final['Modelo'].tolist()\n",
        "f1_scores = comparison_final['Test F1'].tolist()\n",
        "types = comparison_final['Tipo'].tolist()\n",
        "\n",
        "colors = ['coral' if t == 'Cl√°sico' else 'steelblue' for t in types]\n",
        "bars = ax.barh(models_sorted, f1_scores, color=colors)\n",
        "\n",
        "ax.set_xlabel('Test F1 Score')\n",
        "ax.set_title('Comparaci√≥n Final: Todos los Modelos')\n",
        "ax.set_xlim([0.5, 1.0])\n",
        "\n",
        "for i, (bar, f1) in enumerate(zip(bars, f1_scores)):\n",
        "    ax.text(f1 + 0.01, bar.get_y() + bar.get_height()/2, f'{f1:.3f}', \n",
        "            va='center', fontweight='bold')\n",
        "\n",
        "# Leyenda\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor='coral', label='T√©cnicas Cl√°sicas'),\n",
        "                   Patch(facecolor='steelblue', label='Deep Learning')]\n",
        "ax.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/03_final_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Conclusiones\n",
        "\n",
        "### Resumen de resultados:\n",
        "\n",
        "**T√©cnicas Cl√°sicas (descriptores manuales + ML):**\n",
        "- Requieren dise√±o manual de caracter√≠sticas (HOG, LBP, GLCM, etc.)\n",
        "- Menor tiempo de entrenamiento\n",
        "- Interpretabilidad: podemos analizar qu√© caracter√≠sticas son importantes\n",
        "- Buenos resultados con datasets peque√±os\n",
        "\n",
        "**Deep Learning (CNN):**\n",
        "- Aprende caracter√≠sticas autom√°ticamente\n",
        "- Mayor tiempo de entrenamiento (especialmente sin GPU)\n",
        "- Potencial de mejor rendimiento con m√°s datos y √©pocas\n",
        "- Menos interpretable (\"caja negra\")\n",
        "\n",
        "### Observaciones:\n",
        "1. El desbalance de clases afecta el rendimiento de todos los modelos\n",
        "2. La normalizaci√≥n y PCA mejoran significativamente los resultados de modelos cl√°sicos\n",
        "3. La CNN requiere m√°s √©pocas para alcanzar su potencial completo\n",
        "4. Los descriptores de textura (LBP, GLCM) son particularmente √∫tiles para radiograf√≠as\n",
        "\n",
        "### Recomendaciones:\n",
        "- Para producci√≥n: Entrenar CNN con m√°s √©pocas (30-50) y data augmentation\n",
        "- Para interpretabilidad: Usar Random Forest o SVM lineal\n",
        "- Considerar t√©cnicas de balanceo de clases (SMOTE, pesos de clase)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar modelo CNN\n",
        "from src.deep_learning.training import save_model\n",
        "\n",
        "os.makedirs('../models', exist_ok=True)\n",
        "save_model(cnn_result['model'], '../models/simple_cnn.pt', history=cnn_result.get('history'))\n",
        "\n",
        "print(\"\\n‚úì Resultados guardados en ../results/\")\n",
        "print(\"  - 03_normalization.png\")\n",
        "print(\"  - 03_pca_variance.png\")\n",
        "print(\"  - 03_model_comparison.png\")\n",
        "print(\"  - 03_cross_validation.png\")\n",
        "print(\"  - 03_confusion_matrices.png\")\n",
        "print(\"  - 03_feature_importance.png\")\n",
        "print(\"  - 03_cnn_training.png\")\n",
        "print(\"  - 03_cnn_evaluation.png\")\n",
        "print(\"  - 03_final_comparison.png\")\n",
        "print(\"\\n‚úì Modelo guardado en ../models/simple_cnn.pt\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
